\relax 
\citation{5775215}
\citation{7407919}
\citation{8264783}
\citation{7932065}
\citation{7874113}
\citation{8264783}
\citation{7932065}
\citation{7874113}
\citation{Waithe544833}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textbf  {NVIDIA Jetson TX2}.\relax }}{1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:jetson}{{1}{1}}
\citation{jetson}
\citation{Waithe544833}
\citation{redmon2016yolo9000}
\citation{yolov3}
\citation{RFB15a}
\citation{RFB15a}
\citation{8681706}
\citation{RFB15a}
\citation{RFB15a}
\citation{DBLP:journals/corr/ChenPSA17}
\citation{DBLP:journals/corr/ChenPSA17}
\@writefile{toc}{\contentsline {section}{\numberline {2}Literature Review}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Object Detection}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}YOLO}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Semantic Segmentation}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Instance Segmentation}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}UNet}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}DeepLabV3}{2}}
\citation{DBLP:journals/corr/ChenPSA17}
\citation{DBLP:journals/corr/ChenPSA17}
\citation{DBLP:journals/corr/ChenPSA17}
\citation{NIPS2011_4296}
\citation{crfasrnn_ICCV2015}
\citation{higherordercrf_ECCV2016}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textbf  {U-net architecture}\cite  {RFB15a} (example for $32\times 32$ pixels in the lowest resolution). Each blue box corresponds to a multi-channel feature map. The number of channels is denoted on top of the box. The x-y-size is provided at the lower left edge of the box. White boxes represent copied feature maps. The arrows denote the different operations.\relax }}{3}}
\newlabel{fig:unet}{{2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}Conditional Random Fields}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textbf  {Atrous Convolution}. Atrous convolution with kernel size $3\times 3$ and different rates. Standard convolution corresponds to atrous convolution with rate = 1. Employing large value of atrous rate enlarges the modelâ€™s field-of-view, enabling object encoding at multiple scales. Image taken from \cite  {DBLP:journals/corr/ChenPSA17}.\relax }}{3}}
\newlabel{fig:deeplab_atrous_conv}{{3}{3}}
\citation{NIPS2011_4296}
\citation{Teichmann2018ConvolutionalCF}
\citation{NIPS2011_4296}
\citation{Teichmann2018ConvolutionalCF}
\citation{Arnab2017PixelwiseIS}
\citation{Li_2018_ECCV}
\citation{waithe_dominic_2019_2632769}
\citation{waithe_dominic_2019_2632769}
\citation{neuroblastoma_dataset}
\citation{Waithe544833}
\citation{Waithe544833}
\citation{NIPS2011_4296}
\citation{Teichmann2018ConvolutionalCF}
\citation{Waithe544833}
\@writefile{toc}{\contentsline {section}{\numberline {3}Experiment Setup}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Dataset}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Model Architecture}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Detection}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Semantic and Instance Segmentation}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Training Parameters}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Detection}{4}}
\citation{DBLP:journals/corr/abs-1801-00868}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Mean Field Inference\relax }}{5}}
\newlabel{alg:meanfieldinference}{{1}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \textbf  {The Dataset}. Shown here are sample images of neuroblastoma cells (a,c) and C127 cells (b,d) and their corresponding segmentation masks (b,d,f,h). \relax }}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}Semantic and Instance Segmentation}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Evaluation Metrics}{5}}
\citation{Waithe544833}
\citation{Waithe544833}
\citation{redmon2016yolo9000}
\citation{DBLP:journals/corr/ChenPSA17}
\citation{nature_unet}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Computer Hardware}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results and Discussion}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Cell Detection}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Cell Semantic and Instance Segmentation}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \textbf  {Neuroblastoma and C127 Cell Detection}. Shown are some of the detected neuroblastoma and c127 cells using the Tiny YOLO network with the corresponding detection scores.\relax }}{7}}
\newlabel{fig:yolo_results}{{5}{7}}
\citation{NIPS2011_4296}
\citation{Teichmann2018ConvolutionalCF}
\citation{Waithe544833}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \textbf  {YOLO-CRF Semantic Segmentation}. With a Gaussian kernel favoring smoothness, the segmentation results(a,c) of YOLO-CRF are of poor IoU and PQ scores - the nuclei and darker parts of the cell being misclassified as the background. Shown in (b) and (d) are the target segmentations.\relax }}{8}}
\newlabel{fig:yolocrf_results}{{6}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces \textbf  {UNet Semantic Segmentation}. In most cases, with the very narrow gap between the cells, the trained UNet for semantic segmentation performs oversegmentation (a,c), ending up joining multiple cells together. Shown in (b) and (d) are the target segmentations.\relax }}{8}}
\newlabel{fig:unet_results}{{7}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Speed and Memory Usage}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces \textbf  {DeepLabV3 Semantic Segmentation}. Similar to UNet for semantic segmentation, the trained DeepLabV3 model performs oversegmentation (a,c), ending up joining multiple cells together. Shown in (b) and (d) are the target segmentations.\relax }}{9}}
\newlabel{fig:deeplab_results}{{8}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces \textbf  {Weight Penalty Maps}. To force the models to learn the narrow gaps between cells in semantic segmentation, we gave higher penalties for misclassification in those pixels. Shown in this figure are weight penalty maps for two dataset images.\relax }}{9}}
\newlabel{fig:weight_map}{{9}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces \textbf  {Semantic Segmentation with Weight Penalties}. With the introduction of weight penalties, the models for semantic segmentation started to separate adjacent cells better. For UNet, the weight penalties resulted to an undersegmentation of the cells yielding better PQ.\relax }}{9}}
\newlabel{fig:segmentation_with_weight_map}{{10}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces \textbf  {YOLO-UNet-CRF Instance Segmentation.} With the localization from YOLO, the instance segmentation (a,c) of the YOLO-UNet-CRF resolves adjacent cells better, leading to higher PQ. Shown in (b) and (d) are the target instance segmentations.\relax }}{9}}
\newlabel{fig:yolounetcrf_results}{{11}{9}}
\bibstyle{IEEEtran}
\bibdata{ONBI_ROTATION_PROJECT1_DELASPENAS}
\bibcite{5775215}{1}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces \textbf  {Mean Intersection over Union and Panoptic Quality Results}. Although generally obtaining good mean IoU scores on neuroblastoma segmentation, the models have low PQ. The models performed better on the C127 dataset, with the highest mPQ of 0.7731 from YOLO-UNet-CRF.\relax }}{10}}
\newlabel{fig:graph_results}{{12}{10}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{10}}
\bibcite{7407919}{2}
\bibcite{8264783}{3}
\bibcite{7932065}{4}
\bibcite{7874113}{5}
\bibcite{Waithe544833}{6}
\bibcite{jetson}{7}
\bibcite{redmon2016yolo9000}{8}
\bibcite{yolov3}{9}
\bibcite{RFB15a}{10}
\bibcite{8681706}{11}
\bibcite{DBLP:journals/corr/ChenPSA17}{12}
\bibcite{NIPS2011_4296}{13}
\bibcite{crfasrnn_ICCV2015}{14}
\bibcite{higherordercrf_ECCV2016}{15}
\bibcite{Teichmann2018ConvolutionalCF}{16}
\bibcite{Arnab2017PixelwiseIS}{17}
\bibcite{Li_2018_ECCV}{18}
\bibcite{waithe_dominic_2019_2632769}{19}
\bibcite{neuroblastoma_dataset}{20}
\bibcite{DBLP:journals/corr/abs-1801-00868}{21}
\bibcite{nature_unet}{22}
\@writefile{toc}{\contentsline {section}{References}{11}}
