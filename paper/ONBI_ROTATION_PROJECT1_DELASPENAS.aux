\relax 
\citation{Waithe544833}
\citation{jetson}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textbf  {NVIDIA Jetson TX2}.\relax }}{1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:jetson}{{1}{1}}
\citation{redmon2016yolo9000}
\citation{redmon2016yolo9000}
\citation{yolov3}
\citation{RFB15a}
\citation{RFB15a}
\citation{RFB15a}
\citation{DBLP:journals/corr/ChenPSA17}
\citation{DBLP:journals/corr/ChenPSA17}
\@writefile{toc}{\contentsline {section}{\numberline {2}Literature Review}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Semantic Segmentation}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Instance Segmentation}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}YOLO}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textbf  {U-net architecture} \cite  {RFB15a} (example for 32x32 pixels in the lowest resolution). Each blue box corresponds to a multi-channel feature map. The number of channels is denoted on top of the box. The x-y-size is provided at the lower left edge of the box. White boxes represent copied feature maps. The arrows denote the different operations.\relax }}{2}}
\newlabel{fig:unet}{{2}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}UNet}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}DeepLabv3}{2}}
\citation{DBLP:journals/corr/ChenPSA17}
\citation{DBLP:journals/corr/ChenPSA17}
\citation{DBLP:journals/corr/ChenPSA17}
\citation{NIPS2011_4296}
\citation{crfasrnn_ICCV2015}
\citation{higherordercrf_ECCV2016}
\citation{NIPS2011_4296}
\citation{Teichmann2018ConvolutionalCF}
\citation{NIPS2011_4296}
\citation{Teichmann2018ConvolutionalCF}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textbf  {Atrous Convolution}. Atrous convolution with kernel size 3 × 3 and different rates. Standard convolution corresponds to atrous convolution with rate = 1. Employing large value of atrous rate enlarges the model’s field-of-view, enabling object encoding at multiple scales. Image taken from \cite  {DBLP:journals/corr/ChenPSA17}.\relax }}{3}}
\newlabel{fig:deeplab_atrous_conv}{{3}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Conditional Random Fields}{3}}
\citation{Arnab2017PixelwiseIS}
\citation{Li_2018_ECCV}
\citation{waithe_dominic_2019_2632769}
\citation{Waithe544833}
\citation{Waithe544833}
\citation{NIPS2011_4296}
\citation{Teichmann2018ConvolutionalCF}
\citation{Waithe544833}
\@writefile{toc}{\contentsline {section}{\numberline {3}Experiment Setup}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Dataset}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Model Architecture}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Detection}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Semantic and Instance Segmentation}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Training Parameters}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Detection}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}Semantic and Instance Segmentation}{4}}
\citation{DBLP:journals/corr/abs-1801-00868}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Mean Field Inference\relax }}{5}}
\newlabel{alg:meanfieldinference}{{1}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \textbf  {The Dataset}. Shown here are sample images of neuroblastoma cells (a,c) and C127 cells (b,d) and their corresponding segmentation masks (b,d,f,h). \relax }}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Evaluation Metrics}{5}}
\citation{Waithe544833}
\citation{Waithe544833}
\citation{redmon2016yolo9000}
\citation{Waithe544833}
\citation{Waithe544833}
\citation{DBLP:journals/corr/ChenPSA17}
\citation{nature_unet}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Computer Hardware}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results and Discussion}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Cell Detection}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Cell Semantic and Instance Segmentation}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \textbf  {Neuroblastoma and C127 Cell Detection}. Shown are some of the detected neuroblastoma (a,b) and c127 (c,d) cells using the Tiny YOLO network with the corresponding detection scores\relax }}{7}}
\newlabel{fig:yolo_results}{{5}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \textbf  {YOLO version 2 Detection Times.} Comparing with the full YOLO in \cite  {Waithe544833}, the trained Tiny YOLO models performed faster detections.\relax }}{8}}
\newlabel{fig:yolo_runtimes}{{6}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces \textbf  {YOLO-CRF Neuroblastoma Semantic Segmentation}. With a Gaussian kernel favoring smoothness, the segmentation results(a) of YOLO-CRF are of poor IoU score and panoptic quality - the nuclei and darker parts of the cell being misclassified as the background. Shown in (b) is the target segmentation.\relax }}{8}}
\newlabel{fig:yolocrf_results}{{7}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces \textbf  {UNet Neuroblastoma Semantic Segmentation}. In most cases, with the very narrow gap between the neuroblastoma cells, the trained UNet for semantic segmentation performs oversegmentation (a), ending up joining multiple cells together. Shown in (b) is the target segmentation.\relax }}{8}}
\newlabel{fig:unet_results}{{8}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces \textbf  {DeepLabV3 Neuroblastoma Semantic Segmentation}. Similar to UNet for semantic segmentation, the trained DeepLabV3 model performs oversegmentation (a), ending up joining multiple cells together. Shown in (b) is the target segmentation.\relax }}{8}}
\newlabel{fig:deeplab_results}{{9}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces \textbf  {Weight Penalty Maps}. To force the models to learn the narrow gaps between cells in semantic segmentation, we gave higher penalties for misclassification in those pixels. Shown in this figure are weight penalty maps for two of the training images.\relax }}{8}}
\newlabel{fig:weight_map}{{10}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces \textbf  {Neuroblastoma Semantic Segmentation with Weight Penalties}. With the introduction of weight penalties, the models for semantic segmentation started to separate adjacent cells better. For UNet (a), the weight penalties resulted to an undersegmentation of the neuroblastoma cells yielding to better instance segmentation.\relax }}{8}}
\newlabel{fig:segmentation_with_weight_map}{{11}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Performance Tests on the NVIDIA Jetson TX2}{8}}
\bibstyle{IEEEtran}
\bibdata{ONBI_ROTATION_PROJECT1_DELASPENAS}
\bibcite{Waithe544833}{1}
\bibcite{jetson}{2}
\bibcite{redmon2016yolo9000}{3}
\bibcite{yolov3}{4}
\bibcite{RFB15a}{5}
\bibcite{DBLP:journals/corr/ChenPSA17}{6}
\bibcite{NIPS2011_4296}{7}
\bibcite{crfasrnn_ICCV2015}{8}
\bibcite{higherordercrf_ECCV2016}{9}
\bibcite{Teichmann2018ConvolutionalCF}{10}
\bibcite{Arnab2017PixelwiseIS}{11}
\bibcite{Li_2018_ECCV}{12}
\bibcite{waithe_dominic_2019_2632769}{13}
\bibcite{DBLP:journals/corr/abs-1801-00868}{14}
\bibcite{nature_unet}{15}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces \textbf  {Mean Intersection over Union, and Panoptic Quality Results}.\relax }}{9}}
\newlabel{fig:graph_results}{{12}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces \textbf  {Performance on a Constrained Environment.} The cell detection and segmentation algorithms were benchmarked for speed and memory usage on the NVIDIA Jetson TX2.\relax }}{9}}
\newlabel{fig:performance_jetson}{{13}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{9}}
\@writefile{toc}{\contentsline {section}{References}{9}}
